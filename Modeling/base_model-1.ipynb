{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "book_data = pd.read_csv('prepared_bookdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "book_data.rename(columns={'authors': 'Authors', 'description': 'Description', 'publisher': 'Publisher', 'publishedDate':'Published Date', 'rating': 'Rating', 'categories':'Categories', 'ratingsCount': 'Ratings Count'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine relevant text fields into a single text input \n",
    "book_data['combined_text'] = book_data.apply(lambda row: ' '.join([\n",
    "    str(row['Title']),\n",
    "    str(row['Description']),\n",
    "    str(row['Authors']),\n",
    "    str(row['Publisher']),\n",
    "    str(row['Published Date']),\n",
    "    str(row['Categories'])\n",
    "]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from book titles to their indices\n",
    "indices = pd.Series(book_data.index, index=book_data['Title']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform documents into TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(book_data['combined_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity\n",
    "def calculate_similarity_on_demand(idx, tfidf_matrix):\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define recommendation function to find similar books\n",
    "def get_recommendations_on_demand(query, search_by= 'title', n_recommendations=10):\n",
    "    sim_scores = None\n",
    "    if search_by == 'title':\n",
    "        # Filter books where title starts with the query\n",
    "        filtered_indices = book_data[book_data['Title'].str.startswith(query, na=False)].index\n",
    "        sim_scores = np.zeros(len(book_data))  # Initialize similarity scores array\n",
    "        for idx in filtered_indices:\n",
    "            sim_scores += calculate_similarity_on_demand(idx, tfidf_matrix)\n",
    "        sim_scores /= len(filtered_indices)  # Average similarity scores across filtered books\n",
    "    elif search_by == 'Authors':\n",
    "        # Filter books where author contains the query\n",
    "        filtered_indices = book_data[book_data['Authors'].str.contains(query, case=False, regex=False)].index\n",
    "        sim_scores = np.zeros(len(book_data))  # Initialize similarity scores array\n",
    "        for idx in filtered_indices:\n",
    "            sim_scores += calculate_similarity_on_demand(idx, tfidf_matrix)\n",
    "        sim_scores /= len(filtered_indices)  # Average similarity scores across filtered books\n",
    "    \n",
    "    if sim_scores is not None:\n",
    "        sim_scores = list(enumerate(sim_scores))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        book_indices = [i[0] for i in sim_scores[:n_recommendations]]\n",
    "        \n",
    "        recommendations = book_data[['Title', 'Authors', 'Categories', 'Rating', 'Ratings Count', 'Published Date']].iloc[book_indices]\n",
    "        recommendations['Similarity Score'] = [score for _, score in sim_scores[:n_recommendations]]\n",
    "        \n",
    "        return recommendations\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no valid search_by option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean author names by removing the square brackets\n",
    "book_data['Authors'] = book_data['Authors'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean category names (if needed)\n",
    "book_data['Categories'] = book_data['Categories'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an example\n",
    "example_title = book_data['Title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = get_recommendations_on_demand(example_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Evaluation Part ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict ratings for each user-book pair based on similarities ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from book titles to indices\n",
    "indices = pd.Series(book_data.index, index=book_data['Title']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between items\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the predicted rating of a book for a user\n",
    "def predict_rating(user_id, book_index, user_ratings, sim_matrix):\n",
    "    sim_scores = sim_matrix[book_index]\n",
    "    user_rated_indices = user_ratings[user_ratings['User_id'] == user_id].index\n",
    "    valid_indices = [i for i in user_rated_indices if i < len(sim_scores)]\n",
    "    user_ratings_values = user_ratings.loc[valid_indices, 'Rating'].values\n",
    "    if len(user_ratings_values) == 0:\n",
    "        return np.mean(user_ratings['Rating'])  # Return the global average if no ratings\n",
    "    relevant_sim_scores = sim_scores[valid_indices]\n",
    "    if np.sum(relevant_sim_scores) == 0:\n",
    "        return np.mean(user_ratings['Rating'])  # Return the global average if no similarities\n",
    "    weighted_sum = np.dot(relevant_sim_scores, user_ratings_values)\n",
    "    sum_of_sim_scores = np.sum(relevant_sim_scores)\n",
    "    return weighted_sum / sum_of_sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all user-item pairs\n",
    "user_ids = book_data['User_id'].unique()\n",
    "predictions = []\n",
    "for user_id in user_ids:\n",
    "    user_ratings = book_data[book_data['User_id'] == user_id]\n",
    "    for index, row in user_ratings.iterrows():\n",
    "        if row['Title'] not in indices:\n",
    "            continue\n",
    "        book_index = indices[row['Title']]\n",
    "        predicted_rating = predict_rating(user_id, book_index, book_data, cosine_sim)\n",
    "        predictions.append((user_id, row['Title'], predicted_rating, row['Rating']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with predictions and actual ratings\n",
    "pred_df = pd.DataFrame(predictions, columns=['User_id', 'Title', 'Predicted_Rating', 'Actual_Rating'])\n",
    "pred_top10 = pred_df.head(10)\n",
    "pred_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(pred_df['Predicted_Rating'], pred_df['Actual_Rating']))\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(pred_df['Actual_Rating'], pred_df['Predicted_Rating'])\n",
    "\n",
    "print(f\"RMSE, {rmse}\")\n",
    "print(f\"MAE, {mae}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
